{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa792d2ba1564e10a9034728edf02640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33bd36a590b54198b868f2c5ef0a81a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aabed3efb2834d8188761d0ea586e093",
              "IPY_MODEL_29b61e14aea84fdaa220ca5625c21a1f"
            ]
          }
        },
        "33bd36a590b54198b868f2c5ef0a81a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aabed3efb2834d8188761d0ea586e093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1dfb7246d52c4f838bef521135a4c86b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61147f44ea5d446da3f4e30771dfdeaf"
          }
        },
        "29b61e14aea84fdaa220ca5625c21a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9315e07ff3f0404b805c377866c6ccec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 155kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ef6ffc4af6a4a66b9b22cf7a75d3df5"
          }
        },
        "1dfb7246d52c4f838bef521135a4c86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61147f44ea5d446da3f4e30771dfdeaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9315e07ff3f0404b805c377866c6ccec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ef6ffc4af6a4a66b9b22cf7a75d3df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27772b8cde084581a496d8efb51f3c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b188f703ba545dea70b2ef906c70892",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_040a3446cadd4403a28369d15ddf3fbc",
              "IPY_MODEL_abd8b136445e43ed9c0896403b861a2c"
            ]
          }
        },
        "7b188f703ba545dea70b2ef906c70892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "040a3446cadd4403a28369d15ddf3fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a9231e7f4ab4dfbbad9d75a0e8075da",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9d9bc8f71ad48eab9590fc96782c13d"
          }
        },
        "abd8b136445e43ed9c0896403b861a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c2f3b72491840698d23bdf9e1fb2038",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 66.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c288a512ad3145279effe8675b87067d"
          }
        },
        "5a9231e7f4ab4dfbbad9d75a0e8075da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9d9bc8f71ad48eab9590fc96782c13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c2f3b72491840698d23bdf9e1fb2038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c288a512ad3145279effe8675b87067d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "195fa4ac00fe43d88c3245749f2bcfb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c1f8f8e5a9942f29743ff5c1150ba0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1751ba09b4540baba7a91221f889242",
              "IPY_MODEL_dba49cef3bba4ad4ab1656031d380d25"
            ]
          }
        },
        "7c1f8f8e5a9942f29743ff5c1150ba0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1751ba09b4540baba7a91221f889242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_830131d3f6af4852a893dd81723eddac",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5a2c41ab56b45c4995d8b61a3f63b0e"
          }
        },
        "dba49cef3bba4ad4ab1656031d380d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87fe0f1b569f44bb8e8fe7d38d0d491f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.81MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1dc3e85e68a4b218f714a1bbc4ef09a"
          }
        },
        "830131d3f6af4852a893dd81723eddac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5a2c41ab56b45c4995d8b61a3f63b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87fe0f1b569f44bb8e8fe7d38d0d491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1dc3e85e68a4b218f714a1bbc4ef09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a426e4eee084d8097c9e072a6bd4f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c2d8f518a83474c82fcda3fbcffd6aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9cec478887c4e0e8cc6debc35fac517",
              "IPY_MODEL_12f6bea36a454bd7b6b86abcef97c5ab"
            ]
          }
        },
        "1c2d8f518a83474c82fcda3fbcffd6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9cec478887c4e0e8cc6debc35fac517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88d108c9a3aa4d4aae69310348ef9a3f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d16d778321564dc3a04f9577bac559b5"
          }
        },
        "12f6bea36a454bd7b6b86abcef97c5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4353b2f70a0b417aacd821f83aa771f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 6.20kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b81a1c9250344daa890ee4ce602e4f8"
          }
        },
        "88d108c9a3aa4d4aae69310348ef9a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d16d778321564dc3a04f9577bac559b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4353b2f70a0b417aacd821f83aa771f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b81a1c9250344daa890ee4ce602e4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f304fe90e11a4974b8224a6d743203b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_404683109aff4b52b527297cacdc838c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_332bfeeee04c4bf1a47fd8b222c696d8",
              "IPY_MODEL_24a51ef7d61e47c1be1e983d58bd1ae6"
            ]
          }
        },
        "404683109aff4b52b527297cacdc838c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "332bfeeee04c4bf1a47fd8b222c696d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d81c5b5d44e84cc2ad51a1ebd1007254",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26642ffb1ca74e3ba80f95a38f3d56a3"
          }
        },
        "24a51ef7d61e47c1be1e983d58bd1ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f28361e7972743458b81e234e8301ffd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 38.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b7cf9fbe5524fe69a398073513cee3c"
          }
        },
        "d81c5b5d44e84cc2ad51a1ebd1007254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26642ffb1ca74e3ba80f95a38f3d56a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f28361e7972743458b81e234e8301ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b7cf9fbe5524fe69a398073513cee3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DLfNiOqu_BQ"
      },
      "source": [
        "# 문자를 숫자로 표현하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAdk7p-4u89A",
        "outputId": "d4339035-8661-48f5-8a3c-3ca5e9772908"
      },
      "source": [
        "S1='나는 책상 위에 사과를 먹었다'\n",
        "S2='알고 보니 그 사과는 Jason 것이었다'\n",
        "S3='그래서 Jason에게 사과를 했다'\n",
        "\n",
        "# Tokenization : 문장을 의미 있는 부분으로 나누는 과정 -> 띄어쓰기 이용\n",
        "print(S1.split())\n",
        "print(S2.split())\n",
        "print(S3.split())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['나는', '책상', '위에', '사과를', '먹었다']\n",
            "['알고', '보니', '그', '사과는', 'Jason', '것이었다']\n",
            "['그래서', 'Jason에게', '사과를', '했다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBkBaTyQvfcj",
        "outputId": "d1e015a5-e1cd-4e2b-d0d0-badb1f509876"
      },
      "source": [
        "# 겹치는 Token을 따로 모을 필요는 없기 때문에 각 Token에 Index를 지정해 사전 형식으로 모으기\n",
        "token2idx={}\n",
        "index=0\n",
        "\n",
        "for sentence in [S1, S2, S3]:\n",
        "  tokens=sentence.split()\n",
        "  for token in tokens:\n",
        "    if token2idx.get(token)==None: # get(x) 함수는 x라는 Key에 대응되는 Value를 돌려준다\n",
        "      token2idx[token]=index\n",
        "      index+=1\n",
        "\n",
        "print(token2idx)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나는': 0, '책상': 1, '위에': 2, '사과를': 3, '먹었다': 4, '알고': 5, '보니': 6, '그': 7, '사과는': 8, 'Jason': 9, '것이었다': 10, '그래서': 11, 'Jason에게': 12, '했다': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reqZjR1Bwkra"
      },
      "source": [
        "위와 같이 Token을 저장해 놓은 사전인 token2idx를 Vocabulary라 하며, Token의 저장과 관리뿐 아니라 저장할 때 함께 저장한 Index를 이용해 문자를 숫자로 바꾸는 데 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mAbfv7iwwt-",
        "outputId": "799f7488-4bbd-4875-8410-02160f904a52"
      },
      "source": [
        "# Token의 Index 해당 숫자로 각 문장을 바꿔보기\n",
        "def indexed_sentence(sentence):\n",
        "  return[token2idx[token] for token in sentence]\n",
        "\n",
        "print(indexed_sentence(S1.split()))\n",
        "print(indexed_sentence(S2.split()))\n",
        "print(indexed_sentence(S3.split()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4]\n",
            "[5, 6, 7, 8, 9, 10]\n",
            "[11, 12, 3, 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtdL1PiNxK0I"
      },
      "source": [
        "## 2.1 Corpus & Out-of-Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ogAV0iEyEA8"
      },
      "source": [
        "OOV(Out-of-Vocabulary) : Token을 저장해둔 Vocabulary에 Token이 없어서 처음 본 Token이 나오는 현상, 이런 상황을 대비해 특수한 Token인 <unk> Token을 만들어 Vocabulary에 없는 Token이 나올 경우 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaxfTkO_xvC_",
        "outputId": "9c68f699-5eef-4e3f-f970-57651e52e611"
      },
      "source": [
        "# 기존 token 사전에 <unk> token 추가\n",
        "token2idx={t:i+1 for t, i in token2idx.items()} # 0을 만들기 위해 value에 1씩 추가\n",
        "token2idx['<unk>']=0\n",
        "\n",
        "# token이 없을 경우 <unk> token의 0을 반환\n",
        "def indexed_sentence_unk(sentence):\n",
        "  return [token2idx.get(token, token2idx['<unk>']) for token in sentence]\n",
        "\n",
        "S4='나는 책상 위에 배를 먹었다'\n",
        "indexed_sentence_unk(S4.split())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 0, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyp5BjoVy0GL"
      },
      "source": [
        "But 애초에 사전을 풍부하게 만들면 OOV 문제가 해결\n",
        "\n",
        "말뭉치(Corpus) : Token을 모으기 위해 모아 놓은 문장의 모음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iOgCbeay75X"
      },
      "source": [
        "## 2.2 Byte Pair Encoding(BPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGmr-ccDzFaq"
      },
      "source": [
        "다른 Tokenization 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EGogv6szNDm",
        "outputId": "3c01485c-e1c1-41f6-b260-41a79e961385"
      },
      "source": [
        "# Character based tokenization\n",
        "idx2char={0:'<pad>', 1:'<unk>'}\n",
        "\n",
        "srt_idx=len(idx2char) # 기존 dict에서 숫자 추가\n",
        "for x in range(32, 127): # 특수문자 및 숫자, 영어\n",
        "  idx2char.update({srt_idx : chr(x)})\n",
        "  srt_idx+=1\n",
        "\n",
        "\n",
        "# 한글 추가\n",
        "for x in range(int('0x3131', 16), int('0x3163', 16)+1): # 모든 완성형 한글\n",
        "  idx2char.update({srt_idx : chr(x)})\n",
        "  srt_idx+=1\n",
        "\n",
        "for x in range(int('0xAC00', 16), int('0xD7A3', 16)+1): # 자모\n",
        "  idx2char.update({srt_idx : chr(x)})\n",
        "  srt_idx+=1\n",
        "\n",
        "char2idx={v:k for k,v in idx2char.items()}\n",
        "print([char2idx.get(c,0) for c in '그래서 Jason에게 사과를 했다'])\n",
        "print([char2idx.get(c,0) for c in 'ㅇㅋ! ㄱㅅㄱㅅ'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[652, 3116, 5552, 2, 44, 67, 85, 81, 80, 6756, 288, 2, 5440, 400, 3600, 2, 10780, 1912]\n",
            "[119, 123, 3, 2, 97, 117, 97, 117]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdfbPIMF1NnT"
      },
      "source": [
        "기존에 있었던 문장은 물론, 줄임말이나 신조어에 대한 OOV 걱정 X & 사전의 사이즈도 크지 않다. But 글자 하나는 보통 특정 의미를 갖고 있지 않아 모델이 글자의 조합에 대한 정보나 의미를 담도록 설계하는 것이 쉽지 않다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG_Htsmm1b8j",
        "outputId": "a03fd28f-eeac-4042-ddd8-b9cf985a412b"
      },
      "source": [
        "# n-gram Tokenization : 글자보다는 좀 더 긴 형태의 Token을 만들어내기 위해 사용하는 방법, 띄어쓰기 포함\n",
        "\n",
        "S1='나는 책상 위에 사과를  먹었다'\n",
        "print([S1[i:i+1] for i in range(len(S1))]) # uni-gram : character based tokenization\n",
        "print([S1[i:i+2] for i in range(len(S1))]) # bi-gram : 2개의 글자를 Token 단위로\n",
        "print([S1[i:i+3] for i in range(len(S1))]) # tri-gram : 3개의 글자를 Token 단위로"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['나', '는', ' ', '책', '상', ' ', '위', '에', ' ', '사', '과', '를', ' ', ' ', '먹', '었', '다']\n",
            "['나는', '는 ', ' 책', '책상', '상 ', ' 위', '위에', '에 ', ' 사', '사과', '과를', '를 ', '  ', ' 먹', '먹었', '었다', '다']\n",
            "['나는 ', '는 책', ' 책상', '책상 ', '상 위', ' 위에', '위에 ', '에 사', ' 사과', '사과를', '과를 ', '를  ', '  먹', ' 먹었', '먹었다', '었다', '다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f20MVHl12ax4"
      },
      "source": [
        "띄어쓰기 기준의 Token에 대해 n-gram을 사용할 경우, 연속적으로 사용되는 용어를 잘 찾아낼 수 있다. But 쓸모 없는 조합이 너무 많이 생성 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrzhlmIp21-1",
        "outputId": "9a90f30a-16c0-4618-c271-6be8ba58e4e4"
      },
      "source": [
        "# BPE(Byte Pair Encoding) : 반복적으로 나오는 데이터의 연속된 패턴을 치환하는 방식\n",
        "import re, collections\n",
        "\n",
        "def get_stats(vocab): \n",
        "    pairs = collections.defaultdict(int) # 딕셔너리(dictionary)와 거의 비슷하지만 key값이 없을 경우 미리 지정해 놓은 초기(default)값을 반환하는 dictionary\n",
        "    for word, freq in vocab.items():\n",
        "        symbols = word.split()\n",
        "        for i in range(len(symbols)-1):\n",
        "            pairs[symbols[i],symbols[i+1]] += freq\n",
        "    return pairs\n",
        "\n",
        "def merge_vocab(pair, v_in):\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "    for word in v_in:\n",
        "        w_out = p.sub(''.join(pair), word)\n",
        "        v_out[w_out] = v_in[word]\n",
        "    return v_out\n",
        "\n",
        "vocab = {'l o w </w>' : 5, 'l o w e r </w>' : 2, 'n e w e s t </w>':6, 'w i d e s t </w>':3} # 단어 횟수를 기록한 사전, 이 때 사전의 단어 글자는 모두 띄어 표현\n",
        "num_merges = 10 # 미리 정해 놓은 횟수만큼 과정 반복\n",
        "\n",
        "for i in range(num_merges):\n",
        "    pairs = get_stats(vocab)\n",
        "    best = max(pairs, key=pairs.get) # 각 단어에 대해 연속된 2개의 글자의 숫자를 세어 가장 많이 나오는 글자 2개의 조합을 찾기\n",
        "    vocab = merge_vocab(best, vocab) # 두 글자를 합쳐 기존의 사전의 단어를 수정\n",
        "    print(f'Step {i + 1}')\n",
        "    print(best)\n",
        "    print(vocab)\n",
        "    print('\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1\n",
            "('e', 's')\n",
            "{'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n",
            "\n",
            "\n",
            "Step 2\n",
            "('es', 't')\n",
            "{'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n",
            "\n",
            "\n",
            "Step 3\n",
            "('est', '</w>')\n",
            "{'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 4\n",
            "('l', 'o')\n",
            "{'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 5\n",
            "('lo', 'w')\n",
            "{'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 6\n",
            "('n', 'e')\n",
            "{'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 7\n",
            "('ne', 'w')\n",
            "{'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 8\n",
            "('new', 'est</w>')\n",
            "{'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 9\n",
            "('low', '</w>')\n",
            "{'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n",
            "\n",
            "\n",
            "Step 10\n",
            "('w', 'i')\n",
            "{'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvaJBgM69D6q"
      },
      "source": [
        "\"est\", \"low\" 등 자주 등장하는 글자의 연속인 subwords를 찾을 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJhRVEPJ9JW_",
        "outputId": "9ac2ee94-8274-4f2e-fc30-209c6ae6c9d9"
      },
      "source": [
        "# 이전의 띄어쓰기나 Character n-gram Tokenization 결과와 비교\n",
        "\n",
        "S1='나는 책상 위에 사과를 먹었다'\n",
        "S2='알고 보니 그 사과는 Jason 것이었다'\n",
        "S3='그래서 Jason에게 사과를 했다'\n",
        "\n",
        "token_counts={} # 언급된 token의 개수 세기\n",
        "index=0\n",
        "\n",
        "for sentence in [S1, S2, S3]:\n",
        "  tokens=sentence.split()\n",
        "  for token in tokens:\n",
        "    if token_counts.get(token)==None:\n",
        "      token_counts[token]=1\n",
        "    else:\n",
        "      token_counts[token]+=1\n",
        "\n",
        "token_counts={\" \".join(token) : counts for token, counts in token_counts.items()}\n",
        "print(token_counts)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사 과 를': 2, '먹 었 다': 1, '알 고': 1, '보 니': 1, '그': 1, '사 과 는': 1, 'J a s o n': 1, '것 이 었 다': 1, '그 래 서': 1, 'J a s o n 에 게': 1, '했 다': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN4MRSAo99oM",
        "outputId": "9caccc34-ea4a-40c9-a0d9-51c993bba540"
      },
      "source": [
        "num_merges=10\n",
        "\n",
        "for i in range(num_merges):\n",
        "  pairs=get_stats(token_counts)\n",
        "  best=max(pairs, key=pairs.get)\n",
        "  token_counts=merge_vocab(best, token_counts)\n",
        "  print(f'Step {i + 1}')\n",
        "  print(best)\n",
        "  print(token_counts)\n",
        "  print('\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1\n",
            "('사', '과')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과 를': 2, '먹 었 다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'J a s o n': 1, '것 이 었 다': 1, '그 래 서': 1, 'J a s o n 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 2\n",
            "('사과', '를')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었 다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'J a s o n': 1, '것 이 었 다': 1, '그 래 서': 1, 'J a s o n 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 3\n",
            "('었', '다')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'J a s o n': 1, '것 이 었다': 1, '그 래 서': 1, 'J a s o n 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 4\n",
            "('J', 'a')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Ja s o n': 1, '것 이 었다': 1, '그 래 서': 1, 'Ja s o n 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 5\n",
            "('Ja', 's')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Jas o n': 1, '것 이 었다': 1, '그 래 서': 1, 'Jas o n 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 6\n",
            "('Jas', 'o')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Jaso n': 1, '것 이 었다': 1, '그 래 서': 1, 'Jaso n 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 7\n",
            "('Jaso', 'n')\n",
            "{'나 는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Jason': 1, '것 이 었다': 1, '그 래 서': 1, 'Jason 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 8\n",
            "('나', '는')\n",
            "{'나는': 1, '책 상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Jason': 1, '것 이 었다': 1, '그 래 서': 1, 'Jason 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 9\n",
            "('책', '상')\n",
            "{'나는': 1, '책상': 1, '위 에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Jason': 1, '것 이 었다': 1, '그 래 서': 1, 'Jason 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n",
            "Step 10\n",
            "('위', '에')\n",
            "{'나는': 1, '책상': 1, '위에': 1, '사과를': 2, '먹 었다': 1, '알 고': 1, '보 니': 1, '그': 1, '사과 는': 1, 'Jason': 1, '것 이 었다': 1, '그 래 서': 1, 'Jason 에 게': 1, '했 다': 1}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzRIx6ZX_6Ug"
      },
      "source": [
        "## 2.3 Word Enbedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KNVPAeKAGLG"
      },
      "source": [
        "문자를 숫자로 표현하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkeT1t3CAICJ",
        "outputId": "806efe3a-34c0-4eb8-8614-47ac352440db"
      },
      "source": [
        "# 원-핫 인코딩 \n",
        "S1='나는 책상 위에 사과를 먹었다'\n",
        "S2='알고 보니 그 사과는 Jason 것이었다'\n",
        "S3='그래서 Jason에게 사과를 했다'\n",
        "\n",
        "token2idx={}\n",
        "index=0\n",
        "\n",
        "for sentence in [S1, S2, S3]:\n",
        "  tokens = sentence.split()\n",
        "  for token in tokens:\n",
        "    if token2idx.get(token) == None:\n",
        "      token2idx[token] = index\n",
        "      index += 1\n",
        "\n",
        "print(token2idx)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나는': 0, '책상': 1, '위에': 2, '사과를': 3, '먹었다': 4, '알고': 5, '보니': 6, '그': 7, '사과는': 8, 'Jason': 9, '것이었다': 10, '그래서': 11, 'Jason에게': 12, '했다': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J8Jgl5hAxzQ",
        "outputId": "af08ab1d-254a-4849-82d6-f0534cab03cd"
      },
      "source": [
        "V = len(token2idx) # 단어 사전의 크기\n",
        "token2vec = [([0 if i != idx else 1 for i in range(V)], idx, token) for token, idx in token2idx.items() ] # 각 Token은 그에 해당하는 Index의 값만 1의 값을 가진 벡터로 표현\n",
        "\n",
        "for x in token2vec: # x에 vector & index 포함\n",
        "  print(\"\\t\".join([str(y) for y in x]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\t0\t나는\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\t1\t책상\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\t2\t위에\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\t3\t사과를\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\t4\t먹었다\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\t5\t알고\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\t6\t보니\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\t7\t그\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\t8\t사과는\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\t9\tJason\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\t10\t것이었다\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\t11\t그래서\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\t12\tJason에게\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\t13\t했다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5OUZXExCLOT",
        "outputId": "e3578c96-ed8a-41f1-d589-f453e62be5f7"
      },
      "source": [
        "# python numpy를 이용해 문장을 원-핫 인코딩으로 바꾸는 방법\n",
        "import numpy as np\n",
        "\n",
        "for sentence in [S1, S2, S3]:\n",
        "  onehot_s=[]\n",
        "  tokens=sentence.split()\n",
        "  for token in tokens:\n",
        "    if token2idx.get(token)!=None:\n",
        "      vector=np.zeros((1,V))\n",
        "      vector[:,token2idx[token]]=1\n",
        "      onehot_s.append(vector)\n",
        "    else:\n",
        "      print(\"UNK\")\n",
        "\n",
        "  print(f\"{sentence} : \")        \n",
        "  print(np.concatenate(onehot_s, axis = 0))\n",
        "  print('\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "나는 책상 위에 사과를 먹었다 : \n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "\n",
            "알고 보니 그 사과는 Jason 것이었다 : \n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\n",
            "\n",
            "그래서 Jason에게 사과를 했다 : \n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWRXSBiNDEIu"
      },
      "source": [
        "## 예제 5-3 데이터 전처리 및 Pre-Trained Embedding Vector를 이용한 Vocabulary 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li1B8cpDDLRS",
        "outputId": "4c4b4d9a-65ba-4388-8e1f-b346bf7e304a"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "# Data Setting : Field 설정을 통해 여러 가지 작업을 미리 할 수 있음\n",
        "TEXT=data.Field(batch_first=True, # batch size를 data shape axis의 가장 앞으로 설정하는 옵션\n",
        "                fix_length=500, # sentence의 길이를 미리 제한하는 욥션\n",
        "                tokenize=str.split, # tokenize를 설정하는 옵션 기본값은 띄어쓰기 기반의 파이썬의 string.split 함수\n",
        "                pad_first=True, # fix_length 대비 짧은 문장의 경우 padding을 해야 하는데 padding을 앞에서 줄 것인지에 대한 옵션\n",
        "                pad_token='[PAD]', # 위에서 설정한 padding에 대한 특수 token 설정\n",
        "                unk_token='[UNK]') # token dictionary에 없는 token이 나왔을 경우 해당 token을 표현하는 특수 token\n",
        "\n",
        "LABEL=data.LabelField(dtype=torch.float) # 가져올 데이터에 대한 type 설정 옵션\n",
        "train_data, test_data=datasets.IMDB.splits(text_field=TEXT, label_field=LABEL)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 44.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSlrH_t5Im84",
        "outputId": "2856f7c6-8313-429f-ee2b-4c4decb37f13"
      },
      "source": [
        "# Data length\n",
        "print(f'Train Data Length : {len(train_data.examples)}') # data.example : 데이터의 개수 확인\n",
        "print(f'Test Data Length : {len(test_data.examples)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Length : 25000\n",
            "Test Data Length : 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58mGJHfuJClE",
        "outputId": "d9129f20-8ce5-42e1-fe02-e5fd3a84ea0f"
      },
      "source": [
        "# Data Fields\n",
        "print(train_data.fields)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': <torchtext.legacy.data.field.Field object at 0x7fba067df210>, 'label': <torchtext.legacy.data.field.LabelField object at 0x7fba5ffa0f10>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FghUU2wHJGXS",
        "outputId": "f75ddc32-faea-4572-eb4b-9cdc6bdc351d"
      },
      "source": [
        "# Data Sample\n",
        "print('---- Data Sample ----')\n",
        "print('Input : ')\n",
        "print(' '.join(vars(train_data.examples[1])['text']),'\\n') # vars() 함수 이용 : 데이터의 값을 직접 확인 가능\n",
        "print('Label : ')\n",
        "print(vars(train_data.examples[1])['label'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---- Data Sample ----\n",
            "Input : \n",
            "This movie is best described or compare to \"Big Fish\" (the movie by Tim Burton). But it's a less glamorous and more in you face tale. And of course here it's not the father, but his grandfather who tells the stories.<br /><br />The movie's narrative also moves back and forth (so the story outline here at IMDb, might tell you more than you would like to read, before watching the movie). It's funny and engaging enough, even though you get from one story to another and have some dramatic moments too. It also surprises you here and there, with things you wouldn't expect. A nice little movie then, that deserves your attention, especially if you like movies like that! :o) \n",
            "\n",
            "Label : \n",
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlZ6Usa2JYzq"
      },
      "source": [
        "# Data Cleansing : Text Data는 Tokenize를 하기 전에 Data를 살펴보고 Cleansing 작업을 해야 한다.\n",
        "import re\n",
        "def PreProcessingText(input_sentence):\n",
        "  input_sentence=input_sentence.lower() # 소문자화\n",
        "  input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
        "  input_sentence = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
        "  input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
        "  if input_sentence:\n",
        "    return input_sentence\n",
        "\n",
        "for example in train_data.examples:\n",
        "  vars(example)['text']=PreProcessingText(' '.join(vars(example)['text'])).split()\n",
        "for example in test_data.examples:\n",
        "  vars(example)['text']=PreProcessingText(' '.join(vars(example)['text'])).split()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKPh0IzLKcJm"
      },
      "source": [
        "# 주어진 data를 이용해 token vocabulary를 만드는 과정\n",
        "model_config={'emb_type' : 'glove', 'emb_dim' : 300}\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 min_freq=2, # vocab에 해당하는 token에 최소한으로 등장하는 횟수에 제한\n",
        "                 max_size=None, # 전체 vocab size 자체에 제한\n",
        "                 vectors=\"glove.6B.300d\") # pre-trained vector를 가져와 vocab에 세팅하는 옵션. 원하는 embedding을 정해 string 형태로 설정하면 됨.\n",
        "\n",
        "LABEL.build_vocab(train_data)\n",
        "model_config['vocab_size']=len(TEXT.vocab)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwModhOKLQy7",
        "outputId": "2fbd1fa2-be23-4302-bc7d-663cae3e7d3d"
      },
      "source": [
        "# Vocabulary Info\n",
        "print(f'Vocab Size : {len(TEXT.vocab)}')\n",
        "\n",
        "print('Vocab Examples : ')\n",
        "for idx, (k, v) in enumerate(TEXT.vocab.stoi.items()):\n",
        "  if idx >= 10:\n",
        "    break    \n",
        "  print('\\t', k, v)\n",
        "\n",
        "print('---------------------------------')\n",
        "\n",
        "# Label Info\n",
        "print(f'Label Size : {len(LABEL.vocab)}')\n",
        "\n",
        "print('Lable Examples : ')\n",
        "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
        "  print('\\t', k, v)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size : 51956\n",
            "Vocab Examples : \n",
            "\t [UNK] 0\n",
            "\t [PAD] 1\n",
            "\t the 2\n",
            "\t and 3\n",
            "\t a 4\n",
            "\t of 5\n",
            "\t to 6\n",
            "\t is 7\n",
            "\t in 8\n",
            "\t it 9\n",
            "---------------------------------\n",
            "Label Size : 2\n",
            "Lable Examples : \n",
            "\t neg 0\n",
            "\t pos 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE4mvmf7sgo9",
        "outputId": "af5fe2ce-80b0-4c5f-8c35-53519e1fced2"
      },
      "source": [
        "# check embedding vectors\n",
        "TEXT.vocab.vectors.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([51956, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZKoeSiQqmET"
      },
      "source": [
        "import random\n",
        "\n",
        "# spliting valid set\n",
        "train_data, valid_data=train_data.split(random_state=random.seed(0), split_ratio=0.8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97F7f5yNsxBG"
      },
      "source": [
        "model_config['batch_size']=30\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator=data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=model_config['batch_size'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSHTi8dtrjf"
      },
      "source": [
        "# 이 데이터로 모델의 feed-forward가 잘되는지 확인\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentenceClassification(nn.Module):\n",
        "    def __init__(self, **model_config):\n",
        "        super(SentenceClassification, self).__init__()\n",
        "\n",
        "        if model_config['emb_type'] == 'glove' or 'fasttext':\n",
        "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                                    model_config['emb_dim'],\n",
        "                                    _weight = TEXT.vocab.vectors)\n",
        "        else:\n",
        "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                                    model_config['emb_dim'])\n",
        "        \n",
        "        self.bidirectional = model_config['bidirectional']\n",
        "        self.num_direction = 2 if model_config['bidirectional'] else 1\n",
        "        self.model_type = model_config['model_type'] \n",
        "\n",
        "        self.RNN = nn.RNN (input_size = model_config['emb_dim'], # 입력받을 data의 크기 : embedding dimension을 설정\n",
        "                           hidden_size = model_config['hidden_dim'],\n",
        "                           dropout=model_config['dropout'], # dropout의 확률\n",
        "                           bidirectional = model_config['bidirectional'], # 양방향 모델을 사용할 경우에 설정\n",
        "                           batch_first = model_config['batch_first']) # data의 제일 처음 axis에 batch_size가 오도록 설정\n",
        "        \n",
        "        self.LSTM= nn.LSTM(input_size = model_config['emb_dim'],\n",
        "                           hidden_size = model_config['hidden_dim'],\n",
        "                           dropout=model_config['dropout'],\n",
        "                           bidirectional = model_config['bidirectional'],\n",
        "                           batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.GRU = nn.GRU (input_size = model_config['emb_dim'],\n",
        "                           hidden_size = model_config['hidden_dim'],\n",
        "                           dropout=model_config['dropout'],\n",
        "                           bidirectional = model_config['bidirectional'],\n",
        "                           batch_first = model_config['batch_first'])\n",
        "    \n",
        "        self.fc = nn.Linear(model_config['hidden_dim'] * self.num_direction, # 분류 문제 : class에 대한 score를 생성하기 위해 FC layer 1개 생성\n",
        "                            model_config['output_dim'])\n",
        "        \n",
        "        self.drop = nn.Dropout(model_config['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        emb = self.emb(x) # emb : (Batch_Size, Max_Seq_Length, Emb_dim)\n",
        "\n",
        "        if self.model_type == 'RNN':\n",
        "            output, hidden = self.RNN(emb) # output : (Batch_Size, Max_Seq_Length, Hidden_dim * num_direction), hidden : (num_direction, Batch_Size, Hidden_dim)\n",
        "        elif self.model_type == 'LSTM':\n",
        "            output, (hidden, cell) = self.LSTM(emb)\n",
        "        elif self.model_type == 'GRU':\n",
        "            output, hidden = self.GRU(emb)\n",
        "        else:\n",
        "            raise NameError('Select model_type in [RNN, LSTM, GRU]')\n",
        "\n",
        "        last_output = output[:,-1,:] # last_output : (Batch_Size, Hidden_dim * num_direction)\n",
        "\n",
        "        return self.fc(self.drop(last_output))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUzE-1i_yOWJ"
      },
      "source": [
        "import sys\n",
        "\n",
        "def train(model, iterator, optimizer, loss_fn, idx_Epoch, **model_params):\n",
        "  Epoch_loss=0\n",
        "  Eplch_acc=0\n",
        "\n",
        "  model.train()\n",
        "  batch_size=model_params['batch_size']\n",
        "\n",
        "  for idx, batch in enumerate(iterator):\n",
        "    optimizer.zero_grad(iterator) # initializing\n",
        "\n",
        "    # forward\n",
        "    predictions=model(batch.text).squeeze()\n",
        "    loss=loss_fn(predictions, batch.label)\n",
        "    acc=binary_accuracy(predictions, batch.label)\n",
        "\n",
        "    sys.stdout.write(\n",
        "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
        "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
        "                    f\"  Loss: {loss.item():.4}\"\\\n",
        "                    f\"  Acc : {acc.item():.4}\"\\\n",
        "                    )\n",
        "    \n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # update epoch performance\n",
        "    Epoch_loss+=loss.item()\n",
        "    Epoch_acc+=acc.item()\n",
        "\n",
        "  return Epoch_loss/len(iterator), Epoch_acc/len(iterator)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7RQXFgQzdjJ"
      },
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "  Epoch_loss=0\n",
        "  Epoch_acc=0\n",
        "\n",
        "  # evaluation mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions=model(batch.text).sqeeze(1)\n",
        "      loss=loss_fn(predictions, batch.label)\n",
        "      acc=binary_accuracy(predictions, batch.label)\n",
        "\n",
        "      Epoch_loss+=loss.item()\n",
        "      Epoch_acc+=acc.item()\n",
        "\n",
        "  return Epoch_loss/len(iterator), Epoch_acc/len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0LzDgIX0BG4"
      },
      "source": [
        "model_config.update(dict(batch_first=True, model_type='RNN', bidirectional=True,\n",
        "                         hidden_dim=128, output_dim=1, dropout=0)) # binary classification : output_dim=1\n",
        "model_config['model_type']='RNN'\n",
        "\n",
        "model=SentenceClassification(**model_config)\n",
        "optimizer=torch.optim.Adam(model.parameters())\n",
        "loss_fn=nn.BCEWithLogitsLoss() # BCEWithLogitsLoss : 내부에서 시그모이드를 적용하기 때문에 Sigmoid Layer를 통과시키지 않은 값을 Input으로 사용"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "A7RnpdnO0nHd",
        "outputId": "0e29f5d6-39a0-419b-ea92-d5810684123d"
      },
      "source": [
        "N_EPOCH=5\n",
        "\n",
        "best_valid_loss=float('inf')\n",
        "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
        "\n",
        "print('---------------------------------')\n",
        "print(f'Model name : {model_name}')\n",
        "print('---------------------------------')\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
        "    print('')\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'./{model_name}.pt') # Early stopping을 위해 Validation Loss가 최저일 때의 모델을 저장해두고, 이를 나중에 불러와 Test Set에서 적용해 성능을 측정\n",
        "        print(f'\\t Saved at {epoch}-epoch')\n",
        "\n",
        "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
        "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Model name : bi-RNN_glove\n",
            "---------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9882828323c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-e154d0b7e154>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, loss_fn, idx_Epoch, **model_params)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# initializing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'yankland'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC20Zr6n3lpg"
      },
      "source": [
        "## 예제 5.5 Pre-Trained BERT Model을 이용한 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKP4tOlI3rDJ",
        "outputId": "66c7376c-baec-4e48-8467-37b03d11668a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmo3Nj274CYj"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250,
          "referenced_widgets": [
            "fa792d2ba1564e10a9034728edf02640",
            "33bd36a590b54198b868f2c5ef0a81a0",
            "aabed3efb2834d8188761d0ea586e093",
            "29b61e14aea84fdaa220ca5625c21a1f",
            "1dfb7246d52c4f838bef521135a4c86b",
            "61147f44ea5d446da3f4e30771dfdeaf",
            "9315e07ff3f0404b805c377866c6ccec",
            "5ef6ffc4af6a4a66b9b22cf7a75d3df5",
            "27772b8cde084581a496d8efb51f3c03",
            "7b188f703ba545dea70b2ef906c70892",
            "040a3446cadd4403a28369d15ddf3fbc",
            "abd8b136445e43ed9c0896403b861a2c",
            "5a9231e7f4ab4dfbbad9d75a0e8075da",
            "a9d9bc8f71ad48eab9590fc96782c13d",
            "7c2f3b72491840698d23bdf9e1fb2038",
            "c288a512ad3145279effe8675b87067d",
            "195fa4ac00fe43d88c3245749f2bcfb7",
            "7c1f8f8e5a9942f29743ff5c1150ba0e",
            "e1751ba09b4540baba7a91221f889242",
            "dba49cef3bba4ad4ab1656031d380d25",
            "830131d3f6af4852a893dd81723eddac",
            "a5a2c41ab56b45c4995d8b61a3f63b0e",
            "87fe0f1b569f44bb8e8fe7d38d0d491f",
            "c1dc3e85e68a4b218f714a1bbc4ef09a",
            "3a426e4eee084d8097c9e072a6bd4f0a",
            "1c2d8f518a83474c82fcda3fbcffd6aa",
            "c9cec478887c4e0e8cc6debc35fac517",
            "12f6bea36a454bd7b6b86abcef97c5ab",
            "88d108c9a3aa4d4aae69310348ef9a3f",
            "d16d778321564dc3a04f9577bac559b5",
            "4353b2f70a0b417aacd821f83aa771f6",
            "2b81a1c9250344daa890ee4ce602e4f8"
          ]
        },
        "id": "oP385QTD4LPc",
        "outputId": "41247e00-8174-43ff-b7ce-146d624059b5"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "print(len(tokenizer.vocab))\n",
        "\n",
        "max_input_length=tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "print(max_input_length)\n",
        "\n",
        "def new_tokenizer(sentence):\n",
        "  tokens=tokenizer.tokenize(sentence)\n",
        "  tokens=tokens[:max_input_length-2] # 문장의 앞에는 [CLS], 문장의 맨 뒤에는 [SEP] Token을 추가해야 하기 때문에 2개의 special token이 들어갈 자리 2개 미리 빼둠\n",
        "  return tokens"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa792d2ba1564e10a9034728edf02640",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27772b8cde084581a496d8efb51f3c03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "195fa4ac00fe43d88c3245749f2bcfb7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a426e4eee084d8097c9e072a6bd4f0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "30522\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyepNj_a7KxO"
      },
      "source": [
        "# 기본적인 전처리 & token을 index로 바꿔주는 과정\n",
        "def PreProcessingText(input_sentence):\n",
        "    input_sentence = input_sentence.lower() # 소문자화\n",
        "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
        "    input_sentence = re.sub('[!\"$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
        "    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
        "    if input_sentence:\n",
        "        return input_sentence\n",
        "\n",
        "def PreProc(list_sentence): # BERT가 이미 갖고 있는 vocab를 사용해야 하기 때문에 전처리 과정에서 벡터 변환\n",
        "    return [tokenizer.convert_tokens_to_ids(PreProcessingText(x)) for x in list_sentence]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAg7n-_T7l9K"
      },
      "source": [
        "TEXT=data.Field(batch_first=True, use_vocab=False,\n",
        "                tokenize=new_tokenizer, # 앞서 불러온 pre-trained BERT의 tokenizer를 가져와 사용한 후 앞 510개의 token만 골라 가져오는 함수로 수정해 대체\n",
        "                preprocessing=PreProc, # data.Field의 preprocessing 옵션을 이용해 전처리 & Indexing\n",
        "                init_token=tokenizer.cls_token_id,\n",
        "                eos_token=tokenizer.sep_token_id,\n",
        "                pad_token=tokenizer.pad_token_id,\n",
        "                unk_token=tokenizer.unk_token_id)\n",
        "LABEL=data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt9iF-RN8ev9"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "LABEL.build_vocab(train_data)\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(0), split_ratio=0.8)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEjl6jRY8ms-",
        "outputId": "8aee96e2-a13c-4a11-833f-bff006e6927d"
      },
      "source": [
        "# Data Length\n",
        "print(f'Train Data Length : {len(train_data.examples)}')\n",
        "print(f'Test Data Length : {len(test_data.examples)}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Length : 20000\n",
            "Test Data Length : 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEwZDHba8t0u",
        "outputId": "4f72ada5-8189-4579-de67-b57da0d7bc61"
      },
      "source": [
        "# Data Fields\n",
        "train_data.fields"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': <torchtext.legacy.data.field.LabelField at 0x7fb98da6b690>,\n",
              " 'text': <torchtext.legacy.data.field.Field at 0x7fb98e1e7790>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RNoM0vs8vJM",
        "outputId": "83034dc3-8abf-4de8-a761-1fc4b03fb5b3"
      },
      "source": [
        "# Data Sample\n",
        "print('---- Data Sample ----')\n",
        "print('Input : ')\n",
        "print(tokenizer.convert_ids_to_tokens(vars(train_data.examples[2])['text']))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---- Data Sample ----\n",
            "Input : \n",
            "['somewhere', 'in', 'his', 'non', '[UNK]', 'fiction', 'book', 'dans', '##e', 'mac', '##ab', '##re', '[UNK]', 'stephen', 'king', 'suggests', 'that', 'one', 'secret', 'of', 'writing', 'scary', 'stories', 'is', 'to', 'avoid', 'showing', 'your', 'readers', 'exactly', 'what', 'horrible', 'thing', 'is', 'waiting', 'behind', 'the', 'door', 'to', 'get', 'them', '[UNK]', 'if', 'at', 'last', 'the', 'door', 'bursts', 'open', 'and', 'a', 'bug', 'ten', 'feet', 'tall', 'lu', '##rch', '##es', 'through', '[UNK]', 'the', 'reader', 'may', 'be', 'a', 'little', 'scared', '[UNK]', 'but', 'he', \"'\", 'll', 'also', 'think', '[UNK]', '[UNK]', 'well', '[UNK]', 'i', 'can', 'deal', 'with', 'that', '[UNK]', 'at', 'least', 'it', 'wasn', \"'\", 't', 'a', 'hundred', 'feet', 'tall', '[UNK]', '[UNK]', 'there', \"'\", 's', 'nothing', 'more', 'frightening', 'than', 'what', 'lu', '##rks', '[UNK]', 'unseen', 'and', 'unknown', '[UNK]', 'just', 'on', 'the', 'other', 'side', 'of', 'that', 'tightly', 'closed', 'door', '[UNK]', 'waiting', 'to', 'get', 'you', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', 'the', 'haunting', 'is', 'so', 'completely', 'mis', '##con', '##ce', '##ive', '##d', 'that', 'director', 'jan', 'de', 'bon', '##t', 'more', 'or', 'less', 'starts', 'off', 'his', 'movie', 'by', 'metaphor', '##ically', 'throwing', 'open', 'that', 'door', 'himself', 'and', 'yelling', '[UNK]', '[UNK]', 'look', '[UNK]', 'everybody', '[UNK]', 'look', '[UNK]', 'it', \"'\", 's', 'a', 'ten', '[UNK]', 'foot', '[UNK]', 'tall', 'bug', '[UNK]', 'isn', \"'\", 't', 'that', 'scary', '[UNK]', '[UNK]', '[UNK]', 'the', 'law', 'of', 'dim', '##ini', '##shing', 'returns', 'immediately', 'kicks', 'in', '[UNK]', 'by', 'the', 'end', 'of', 'the', 'movie', '[UNK]', 'the', 'director', 'is', '[UNK]', 'so', 'to', 'speak', '[UNK]', 'jumping', 'up', 'and', 'down', '[UNK]', 'banging', 'his', 'c', '##gi', 'pots', 'and', 'pan', '##s', 'madly', '[UNK]', 'and', 'hoarse', '##ly', 'screaming', '[UNK]', '[UNK]', 'look', '[UNK]', 'everyone', '[UNK]', 'look', '[UNK]', 'here', 'come', 'ten', 'hundred', '[UNK]', 'foot', '[UNK]', 'tall', 'bugs', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'and', 'now', '[UNK]', 'here', 'come', 'a', 'hundred', 'thousand', '[UNK]', 'foot', '[UNK]', 'tall', 'bugs', '[UNK]', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', 'the', 'filmmakers', 'apparently', 'believed', 'that', 'special', 'effects', 'alone', 'could', 'compensate', 'for', 'all', 'the', 'other', 'short', '##coming', '##s', 'in', 'this', 'endeavor', '[UNK]', 'and', 'there', 'are', 'many', '[UNK]', '[UNK]', 'they', 'can', \"'\", 't', 'and', 'don', \"'\", 't', '[UNK]', 'in', 'fact', '[UNK]', 'impressive', 'as', 'they', 'are', '[UNK]', 'the', 'special', 'effects', 'are', 'so', 'insistent', 'and', 'ob', '##tr', '##us', '##ive', 'that', 'the', 'distracted', 'viewer', 'winds', 'up', 'staring', 'at', 'them', '[UNK]', '[UNK]', 'whether', 'in', 'admiration', 'or', 'annoyance', '[UNK]', '[UNK]', 'instead', 'of', 'being', 'immersed', 'in', 'a', 'story', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', 'for', 'me', '[UNK]', 'the', 'nad', '##ir', 'of', 'this', 'film', \"'\", 's', 'sheer', 'stupidity', 'comes', 'when', 'a', 'statue', '[UNK]', 'with', '[UNK]', 'blood', '[UNK]', 'gus', '##hing', 'from', 'its', 'mouth', '[UNK]', 'tries', 'to', 'drown', 'liam', 'nee', '##son', '[UNK]', 'as', 'dr', '[UNK]', 'marrow', '[UNK]', 'in', 'a', 'fountain', '[UNK]', 'the', 'filmmakers', 'clearly', 'didn', \"'\", 't', 'know', 'what', 'to', 'do', 'with', 'this', 'alleged', 'idea', 'once', 'they', 'had', 'it', '[UNK]', 'so', 'they', 'just', 'have', 'nee', '##son', 'thrash', 'around', 'in', 'the', 'water', 'a', 'bit', '[UNK]', 'fl', '##ailing', 'his', 'arms', 'and', 'going', 'g', '##lu', '##g', '[UNK]', 'g', '##lu', '##g', '[UNK]', 'by', 'the', 'next', 'scene', '[UNK]', 'the', 'good', 'doctor', 'has', 'apparently', 'dried', 'himself', 'off', 'and', '[UNK]', 'ho', 'hum', '[UNK]', 'forgotten', 'all', 'about', 'the', 'annoying', 'incident', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', '[UNK]', 'br', '[UNK]', '[UNK]', 'shirley', 'jackson', \"'\", 's', 'novel', 'seems', 'to', 'have', 'been', 'dumb', '##ed', '[UNK]', 'down']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVhbmpSC8yXp",
        "outputId": "875bf058-0c74-415c-ed2b-7155d63c8507"
      },
      "source": [
        "# Label Info\n",
        "print(f'Label Size : {len(LABEL.vocab)}')\n",
        "\n",
        "print('Lable Examples : ')\n",
        "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
        "    print('\\t', k, v)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Size : 2\n",
            "Lable Examples : \n",
            "\t neg 0\n",
            "\t pos 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q57ddweI82j9"
      },
      "source": [
        "model_config = {}\n",
        "model_config['batch_size'] = 10\n",
        "\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=model_config['batch_size'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "f304fe90e11a4974b8224a6d743203b0",
            "404683109aff4b52b527297cacdc838c",
            "332bfeeee04c4bf1a47fd8b222c696d8",
            "24a51ef7d61e47c1be1e983d58bd1ae6",
            "d81c5b5d44e84cc2ad51a1ebd1007254",
            "26642ffb1ca74e3ba80f95a38f3d56a3",
            "f28361e7972743458b81e234e8301ffd",
            "9b7cf9fbe5524fe69a398073513cee3c"
          ]
        },
        "id": "mmqWC7gt9AoL",
        "outputId": "7d7d28ef-8975-4301-b7db-5ca18afd80bc"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "model_config['emb_dim'] = bert.config.to_dict()['hidden_size']\n",
        "print(model_config['emb_dim'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f304fe90e11a4974b8224a6d743203b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpdZB59v9JMi"
      },
      "source": [
        "class SentenceClassification(nn.Module):\n",
        "    def __init__(self, **model_config):\n",
        "        super(SentenceClassification, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.fc = nn.Linear(model_config['emb_dim'],\n",
        "                            model_config['output_dim'])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        pooled_cls_output = self.bert(x)[1] # output 자체를 쓰는 것이 아니라 pooled_output 사용 (BertModel 기준 두 번째 값 사용)\n",
        "        return self.fc(pooled_cls_output)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q_AEVCJ9a4M"
      },
      "source": [
        "model_config.update(dict(output_dim = 1))\n",
        "\n",
        "model = SentenceClassification(**model_config)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5) # 이미 잘 학습된 BERT 모델 파라미터를 크게 변하게 되면 안되기 때문에 learning rate를 낮춰야 함.\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsoERUY1-P9a",
        "outputId": "f71d9052-ae17-4f9a-f01b-e59fc2533b39"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model) "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109483009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxUhD9Eg_Cph"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    # rounded_preds = torch.argmax(preds, axis=1) \n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZoFQGbs_H-0",
        "outputId": "8643ab6c-3ca6-4c04-fb22-dcdca0362dba"
      },
      "source": [
        "N_EPOCH = 4\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model_name = \"BERT\"\n",
        "\n",
        "print('---------------------------------')\n",
        "print(f'Model name : {model_name}')\n",
        "print('---------------------------------')\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
        "    print('')\n",
        "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn, epoch, **model_config)\n",
        "    print('')\n",
        "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')\n",
        "    # print('')\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
        "        print(f'\\t Model is saved at {epoch}-epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Model name : BERT\n",
            "---------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpJVWUSl_MVU"
      },
      "source": [
        "# Test set\n",
        "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
        "epoch = 0\n",
        "test_loss, test_acc = evaluate(model, test_iterator, loss_fn, epoch, **model_config)\n",
        "print('')\n",
        "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}